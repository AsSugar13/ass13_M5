{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "new_begining.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "L6jxjK7G6eC7",
        "oxF6P69R7QF3",
        "6FErFlS67dvG",
        "Z3ilypsE67gr"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsSugar13/ass13_M5/blob/master/new_begining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXBnXqwL4YmE",
        "colab_type": "code",
        "outputId": "9255a7a7-328d-4efd-be8f-16b6ad33d059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6jxjK7G6eC7",
        "colab_type": "text"
      },
      "source": [
        "# Base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq-K1zyv3dWW",
        "colab_type": "code",
        "outputId": "57599265-22ce-401f-def9-5419112254b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.experimental                       import enable_iterative_imputer\n",
        "from IPython.display                            import display\n",
        "\n",
        "from sklearn.linear_model                       import LinearRegression, Ridge, Lasso, HuberRegressor, SGDRegressor\n",
        "from sklearn.svm                                import SVC, NuSVR, OneClassSVM\n",
        "from sklearn.pipeline                           import Pipeline, FeatureUnion\n",
        "from sklearn.preprocessing                      import OrdinalEncoder, FunctionTransformer, OneHotEncoder,\\\n",
        "                                                       KBinsDiscretizer, LabelEncoder, PolynomialFeatures,\\\n",
        "                                                       StandardScaler, MaxAbsScaler, maxabs_scale, OrdinalEncoder\n",
        "from imblearn.pipeline                          import Pipeline as Pipeline_IMB\n",
        "from sklearn.impute                             import SimpleImputer, IterativeImputer, KNNImputer\n",
        "from sklearn.metrics                            import make_scorer, mean_squared_error\n",
        "from scipy.stats                                import spearmanr\n",
        "from sklearn.model_selection                    import KFold, StratifiedKFold, GroupKFold, TimeSeriesSplit,\\\n",
        "                                                       RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.feature_extraction.text            import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "from sklearn.feature_selection                  import SelectKBest, chi2, SelectFromModel, f_regression\n",
        "from sklearn.decomposition                      import TruncatedSVD\n",
        "\n",
        "from sklearn.linear_model                       import LogisticRegression\n",
        "from sklearn.multioutput                        import MultiOutputClassifier, MultiOutputRegressor\n",
        "from sklearn.multiclass                         import OneVsRestClassifier\n",
        "from sklearn.ensemble                           import RandomForestClassifier, RandomForestRegressor,\\\n",
        "                                                       AdaBoostRegressor, AdaBoostClassifier, GradientBoostingRegressor\n",
        "from sklearn.linear_model                       import ElasticNet, BayesianRidge\n",
        "from sklearn.neural_network                     import MLPRegressor\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection                    import train_test_split, RandomizedSearchCV, GridSearchCV,\\\n",
        "                                                       cross_val_score, cross_val_predict, cross_validate\n",
        "\n",
        "from imblearn                                   import FunctionSampler\n",
        "from imblearn.over_sampling                     import SMOTE, SVMSMOTE, ADASYN\n",
        "from imblearn.combine                           import SMOTETomek\n",
        "\n",
        "import gc\n",
        "import re\n",
        "import pickle\n",
        "sns.set(style=\"white\", color_codes=True)\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "np.random.seed(13)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ila2hyB73dWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_rows', 1000)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', 500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYp9FP163dWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### reading first lines\n",
        "\n",
        "# with open('./sales_train_validation.csv', \"r\") as f:\n",
        "#     for i in range(1):\n",
        "#         print(f.readline())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ1-MbgO3dWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def macd(df, slow):\n",
        "    first, second, slow = slow*12//9, slow*26//9, slow\n",
        "    \n",
        "    first_ewm = df.ewm(span=first, min_periods=first, adjust=False, axis=1).mean().astype('float16')\n",
        "    second_ewm = df.ewm(span=second, min_periods=second, adjust=False, axis=1).mean().astype('float16')\n",
        "    \n",
        "    fast_ema = first_ewm - second_ewm\n",
        "    slow_ema = fast_ema.ewm(span=slow, min_periods=slow, adjust=False, axis=1).mean().astype('float16')\n",
        "    \n",
        "    macd = fast_ema-slow_ema\n",
        "    \n",
        "    return macd\n",
        "\n",
        "def angle(x):\n",
        "    return np.rad2deg(np.arctan(np.polyfit(range(len(x)), x, 1)[0])).astype('float16')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap5U0d2F3dW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_df(def_path='./'):\n",
        "    \n",
        "    # Load dtypes\n",
        "    with open(def_path + 'dtypes.pickle', 'rb') as f:\n",
        "        dtypes = pickle.load(f)\n",
        "        \n",
        "    df = pd.read_csv(def_path + 'sales_train_validation.csv',\n",
        "                     dtype=dtypes\n",
        "#                  , index_col='id'\n",
        "                    )\n",
        "    gc.collect()\n",
        "    return df\n",
        "\n",
        "df = load_df(def_path='./drive/My Drive/Colab Notebooks/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw4xlwsb3dW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display(df.shape)\n",
        "# display(df.info())\n",
        "# display(df.describe())\n",
        "# display(df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFu-hsbm3dXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### define dtype for the 1st time\n",
        "\n",
        "# dtypes = {}\n",
        "\n",
        "# for i, j in zip(df.dtypes.index, df.dtypes):\n",
        "#     if (j == 'int'):\n",
        "# #         df.loc[:, i] = pd.to_numeric(df.loc[:, i], downcast='integer')\n",
        "#         dtypes[i]='uint16'\n",
        "#     elif (j == 'object'):\n",
        "#         dtypes[i] = 'object'\n",
        "\n",
        "# # saving dtype for future ease importing\n",
        "# with open('dtypes.pickle', 'wb') as f:\n",
        "#     pickle.dump(dtypes, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMdXB5dYlsPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### changing dtypes for variables\n",
        "\n",
        "# with open('./drive/My Drive/Colab Notebooks/dtypes.pickle', 'rb') as f:\n",
        "#     dtypes = pickle.load(f)\n",
        "# for i in dtypes.keys():\n",
        "#     if dtypes[i] == 'uint16':\n",
        "#         dtypes[i] = 'float16'\n",
        "# with open('dtypes.pickle', 'wb') as f:\n",
        "#     pickle.dump(dtypes, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psWblDaF3dXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nums = []\n",
        "cats = []\n",
        "\n",
        "for i, j in zip(df.dtypes.index, df.dtypes):\n",
        "    if (j == 'int16'):\n",
        "        nums.append(i)\n",
        "    elif (j == 'object'):\n",
        "        cats.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IpZayHw3dXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### melting data\n",
        "df = df.melt(id_vars=cats, var_name='d', value_name='demand')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngUii0TM3dXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adding_cols(df, lags=[0, 90, 180], macd_angle=False, by_col='id', target_col='demand'):\n",
        "    \n",
        "#     df = df.copy()\n",
        "    \n",
        "    params = []\n",
        "\n",
        "    for lag in lags:\n",
        "        print(lag)\n",
        "    \n",
        "        #rolling mean\n",
        "        for window in [7, 14]:\n",
        "\n",
        "            add_param = df.groupby(by=by_col)[target_col]\\\n",
        "            .transform(lambda x: x.rolling(window).mean()\\\n",
        "            .shift(1+lag)).astype('float16')\n",
        "            \n",
        "            sub_column_name = f'rol_mean_t{window}_l{lag}'\n",
        "            params.append(sub_column_name)\n",
        "            df.loc[:, sub_column_name] = add_param\n",
        "            gc.collect()\n",
        "\n",
        "        #rolling std\n",
        "        for window in [7, 14]:\n",
        "            \n",
        "            add_param = df.groupby(by=by_col)[target_col]\\\n",
        "            .transform(lambda x: x.rolling(window).std()\\\n",
        "            .shift(1+lag)).astype('float16')\n",
        "            \n",
        "            sub_column_name = f'rol_std_t{window}_l{lag}'\n",
        "            params.append(sub_column_name)\n",
        "            df.loc[:, sub_column_name] = add_param\n",
        "            gc.collect()\n",
        "            \n",
        "    #     #rolling max\n",
        "    #     for window in [7, 14, 30]:\n",
        "            \n",
        "    #         add_param = df.groupby(by='item_id')[target_col]\\\n",
        "    #         .transform(lambda x: x.shift(lag))\\\n",
        "    #         .rolling(window).max().astype('float16')\n",
        "            \n",
        "    #         sub_column_name = f'rol_max_t{window}_l{lag}'\n",
        "    #         params.append(sub_column_name)\n",
        "    #         df.loc[:, sub_column_name] = add_param\n",
        "    #         gc.collect()\n",
        "            \n",
        "    #     #rolling min\n",
        "    #     for window in [7, 14, 30]:\n",
        "            \n",
        "    #         add_param = df.groupby(by='item_id')[target_col]\\\n",
        "    #         .transform(lambda x: x.shift(lag))\\\n",
        "    #         .rolling(window).min().astype('float16')\n",
        "            \n",
        "    #         sub_column_name = f'rol_min_t{window}_l{lag}'\n",
        "    #         params.append(sub_column_name)\n",
        "    #         df.loc[:, sub_column_name] = add_param\n",
        "    #         gc.collect()\n",
        "            \n",
        "    #     #rolling skew\n",
        "    #     for window in [7, 14, 30]:\n",
        "            \n",
        "    #         add_param = df.groupby(by='item_id')[target_col]\\\n",
        "    #         .transform(lambda x: x.shift(lag))\\\n",
        "    #         .rolling(window).skew().astype('float16')\n",
        "            \n",
        "    #         sub_column_name = f'rol_skew_t{window}_l{lag}'\n",
        "    #         params.append(sub_column_name)\n",
        "    #         df.loc[:, sub_column_name] = add_param\n",
        "    #         gc.collect()\n",
        "            \n",
        "    #     #rolling kurt\n",
        "    #     for window in [7, 14, 30]:\n",
        "            \n",
        "    #         add_param = df.groupby(by='item_id')[target_col]\\\n",
        "    #         .transform(lambda x: x.shift(lag))\\\n",
        "    #         .rolling(window).kurt().astype('float16')\n",
        "            \n",
        "    #         sub_column_name = f'rol_kurt_t{window}_l{lag}'\n",
        "    #         params.append(sub_column_name)\n",
        "    #         df.loc[:, sub_column_name] = add_param\n",
        "    #         gc.collect()\n",
        "            \n",
        "        #ewm mean    \n",
        "        for window in [7, 14]:\n",
        "            \n",
        "            add_param = df.groupby(by=by_col)[target_col]\\\n",
        "            .transform(lambda x: x.ewm(window).mean()\\\n",
        "            .shift(1+lag)).astype('float16')\n",
        "            \n",
        "            sub_column_name = f'ewm_mean_t{window}_l{lag}'\n",
        "            params.append(sub_column_name)\n",
        "            df.loc[:, sub_column_name] = add_param\n",
        "            gc.collect()\n",
        "            \n",
        "        #ewm std    \n",
        "        for window in [7, 14]:\n",
        "            \n",
        "            add_param = df.groupby(by=by_col)[target_col]\\\n",
        "            .transform(lambda x: x.ewm(window).std()\\\n",
        "            .shift(1+lag)).astype('float16')\n",
        "            \n",
        "            sub_column_name = f'ewm_std_t{window}_l{lag}'\n",
        "            params.append(sub_column_name)\n",
        "            df.loc[:, sub_column_name] = add_param\n",
        "            gc.collect()\n",
        "\n",
        "    #     #macd\n",
        "    #     for short in [4, 7, 9]:\n",
        "    #         add_param = macd(df[nums], short)\n",
        "    #         sub_column_name = f'macd_'+str(short)\n",
        "    #         params.append(sub_column_name)\n",
        "    #         add_param.columns = pd.MultiIndex.from_tuples([(col[0], sub_column_name) for col in add_param.columns])\n",
        "    #         df_out = df_out.join(add_param).sort_index(axis=1)\n",
        "    #         gc.collect()\n",
        "\n",
        "    #         if macd_angle==True:\n",
        "    #             for window in [2, 3, 5]:\n",
        "    #                 add_param = add_param.rolling(window, axis=1).apply(angle, raw=True)\n",
        "    #                 sub_column_name = f'macd_'+str(short)+'_angle_'+str(window)\n",
        "    #                 params.append(sub_column_name)\n",
        "    #                 add_param.columns = pd.MultiIndex.from_tuples([(col[0], sub_column_name) for col in add_param.columns])\n",
        "    #                 df_out = df_out.join(add_param).sort_index(axis=1)\n",
        "    #                 gc.collect()\n",
        "\n",
        "    # gc.collect()\n",
        "    return df, params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uet_-b8n3dXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_calendar(def_path='./'):  \n",
        "    calendar = pd.read_csv(def_path + 'calendar.csv',\n",
        "                           \n",
        "                           usecols=['wday', 'month', 'event_name_1', 'event_type_1',\n",
        "                                    'event_name_2', 'event_type_2',\n",
        "                                    'snap_CA', 'snap_TX', 'snap_WI', 'd'],\n",
        "\n",
        "                           dtype={'wday': 'uint8',\n",
        "                                  'month': 'uint8',\n",
        "                                  'snap_CA': 'uint8',\n",
        "                                  'snap_TX': 'uint8',\n",
        "                                  'snap_WI': 'uint8',                            \n",
        "                                 }\n",
        "                          )\n",
        "    \n",
        "    calendar.fillna('Nothing', inplace=True)\n",
        "    # calendar.drop(['date', 'wm_yr_wk', 'weekday','year'])\n",
        "    \n",
        "    cats_to_encode = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
        "    \n",
        "#####################################################################################################    \n",
        "    event_name_1_in_1d =(calendar['event_name_1'].shift(-1, axis=0).fillna('Nothing')!='Nothing')\n",
        "    event_name_1_in_1d.name = 'event_name_1_in_1d'\n",
        "    cats_to_encode.append('event_name_1_in_1d')\n",
        "    \n",
        "    event_name_1_in_3d =(calendar['event_name_1'].shift(-1, axis=0).fillna('Nothing')!='Nothing')|\\\n",
        "                        (calendar['event_name_1'].shift(-2, axis=0).fillna('Nothing')!='Nothing')|\\\n",
        "                        (calendar['event_name_1'].shift(-3, axis=0).fillna('Nothing')!='Nothing')\n",
        "    event_name_1_in_3d.name = 'event_name_1_in_3d'\n",
        "    cats_to_encode.append('event_name_1_in_3d')\n",
        "\n",
        "    event_name_1_in_7d =(calendar['event_name_1'].shift(-1, axis=0).fillna('Nothing')!='Nothing')|\\\n",
        "                        (calendar['event_name_1'].shift(-2, axis=0).fillna('Nothing')!='Nothing')|\\\n",
        "                        (calendar['event_name_1'].shift(-3, axis=0).fillna('Nothing')!='Nothing')|\\\n",
        "                        (calendar['event_name_1'].shift(-4, axis=0).fillna('Nothing')!='Nothing')|\\\n",
        "                        (calendar['event_name_1'].shift(-5, axis=0).fillna('Nothing')!='Nothing')|\\\n",
        "                        (calendar['event_name_1'].shift(-6, axis=0).fillna('Nothing')!='Nothing')|\\\n",
        "                        (calendar['event_name_1'].shift(-7, axis=0).fillna('Nothing')!='Nothing')\n",
        "    event_name_1_in_7d.name = 'event_name_1_in_7d'\n",
        "    cats_to_encode.append('event_name_1_in_7d')\n",
        "    \n",
        "    calendar = pd.concat([calendar, event_name_1_in_1d, event_name_1_in_3d, event_name_1_in_7d], axis=1)\n",
        "#####################################################################################################\n",
        "\n",
        "#params\n",
        "    params = calendar.columns.tolist()\n",
        "\n",
        "#encoding  cats\n",
        "    encoder = OrdinalEncoder(dtype='uint8')    \n",
        "    calendar.loc[:, cats_to_encode] = encoder.fit_transform(calendar[cats_to_encode])\n",
        "    for i in cats_to_encode:\n",
        "        calendar.loc[:, i] = calendar.loc[:, i].astype('uint8')\n",
        "    \n",
        "    return calendar, params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAQ0fcrtGwJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "df.loc[:, 'demand_log'] = df['demand'].apply(lambda x: np.log1p(x)).astype('float16')\n",
        "df, params_df = adding_cols(df, lags=[0, 30, 180], target_col='demand_log')\n",
        "calendar, params_calendar = load_calendar(def_path='./drive/My Drive/Colab Notebooks/')\n",
        "\n",
        "df = df.merge(calendar, how='left', on='d')\n",
        "del calendar\n",
        "\n",
        "df.dropna(axis=0, inplace=True)\n",
        "print('Completed')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7V0yvjK3dXf",
        "colab_type": "code",
        "outputId": "0d64ebc6-d59d-4833-e7cf-bd01562a9654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# %%time\n",
        "# df, params_df = adding_cols(df, lags=[0, 30, 180])\n",
        "# calendar, params_calendar = load_calendar(def_path='./drive/My Drive/Colab Notebooks/')\n",
        "\n",
        "# df = df.merge(calendar, how='left', on='d')\n",
        "# del calendar\n",
        "\n",
        "# df.dropna(axis=0, inplace=True)\n",
        "# print('Completed')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "30\n",
            "180\n",
            "Completed\n",
            "CPU times: user 22min 22s, sys: 12.1 s, total: 22min 34s\n",
            "Wall time: 22min 36s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxF6P69R7QF3",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUleAoKYDjpq",
        "colab_type": "code",
        "outputId": "b2bd7dbb-6f53-4123-809e-5a37363dcff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "print(gpu_info)\n",
        "\n",
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "# print(!lscpu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun May  3 21:59:08 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XJgNSnJnTjL",
        "colab_type": "code",
        "outputId": "5834e8fc-c8f3-418d-8d18-b5bb7bc09f4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "display(df.head())\n",
        "\n",
        "display(df.id.value_counts().shape)\n",
        "display(df.item_id.value_counts().shape)\n",
        "display(df.dept_id.value_counts().shape)\n",
        "display(df.cat_id.value_counts().shape)\n",
        "display(df.store_id.value_counts().shape)\n",
        "display(df.state_id.value_counts().shape)\n",
        "display(df.d.value_counts().shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d</th>\n",
              "      <th>demand</th>\n",
              "      <th>rol_mean_t7_l0</th>\n",
              "      <th>rol_mean_t14_l0</th>\n",
              "      <th>rol_std_t7_l0</th>\n",
              "      <th>rol_std_t14_l0</th>\n",
              "      <th>ewm_mean_t7_l0</th>\n",
              "      <th>ewm_mean_t14_l0</th>\n",
              "      <th>ewm_std_t7_l0</th>\n",
              "      <th>ewm_std_t14_l0</th>\n",
              "      <th>rol_mean_t7_l30</th>\n",
              "      <th>rol_mean_t14_l30</th>\n",
              "      <th>rol_std_t7_l30</th>\n",
              "      <th>rol_std_t14_l30</th>\n",
              "      <th>ewm_mean_t7_l30</th>\n",
              "      <th>ewm_mean_t14_l30</th>\n",
              "      <th>ewm_std_t7_l30</th>\n",
              "      <th>ewm_std_t14_l30</th>\n",
              "      <th>rol_mean_t7_l180</th>\n",
              "      <th>rol_mean_t14_l180</th>\n",
              "      <th>rol_std_t7_l180</th>\n",
              "      <th>rol_std_t14_l180</th>\n",
              "      <th>ewm_mean_t7_l180</th>\n",
              "      <th>ewm_mean_t14_l180</th>\n",
              "      <th>ewm_std_t7_l180</th>\n",
              "      <th>ewm_std_t14_l180</th>\n",
              "      <th>wday</th>\n",
              "      <th>month</th>\n",
              "      <th>event_name_1</th>\n",
              "      <th>event_type_1</th>\n",
              "      <th>event_name_2</th>\n",
              "      <th>event_type_2</th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "      <th>event_name_1_in_1d</th>\n",
              "      <th>event_name_1_in_3d</th>\n",
              "      <th>event_name_1_in_7d</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5915060</th>\n",
              "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_195</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5915061</th>\n",
              "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_002</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_195</td>\n",
              "      <td>0</td>\n",
              "      <td>0.285645</td>\n",
              "      <td>0.142822</td>\n",
              "      <td>0.488037</td>\n",
              "      <td>0.363037</td>\n",
              "      <td>0.157593</td>\n",
              "      <td>0.151123</td>\n",
              "      <td>0.377197</td>\n",
              "      <td>0.364502</td>\n",
              "      <td>0.142822</td>\n",
              "      <td>0.285645</td>\n",
              "      <td>0.377930</td>\n",
              "      <td>0.468750</td>\n",
              "      <td>0.209961</td>\n",
              "      <td>0.194702</td>\n",
              "      <td>0.421631</td>\n",
              "      <td>0.402832</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5915062</th>\n",
              "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_003</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_195</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5915063</th>\n",
              "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_004</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_195</td>\n",
              "      <td>0</td>\n",
              "      <td>1.286133</td>\n",
              "      <td>1.786133</td>\n",
              "      <td>1.112305</td>\n",
              "      <td>1.528320</td>\n",
              "      <td>1.422852</td>\n",
              "      <td>1.542969</td>\n",
              "      <td>1.405273</td>\n",
              "      <td>1.472656</td>\n",
              "      <td>2.142578</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.772461</td>\n",
              "      <td>1.753906</td>\n",
              "      <td>2.039062</td>\n",
              "      <td>1.716797</td>\n",
              "      <td>1.822266</td>\n",
              "      <td>1.758789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5915064</th>\n",
              "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_005</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_195</td>\n",
              "      <td>0</td>\n",
              "      <td>0.285645</td>\n",
              "      <td>0.714355</td>\n",
              "      <td>0.755859</td>\n",
              "      <td>1.204102</td>\n",
              "      <td>0.553223</td>\n",
              "      <td>0.482910</td>\n",
              "      <td>1.042969</td>\n",
              "      <td>1.035156</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071411</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.267334</td>\n",
              "      <td>0.178711</td>\n",
              "      <td>0.442871</td>\n",
              "      <td>0.812012</td>\n",
              "      <td>1.246094</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    id        item_id    dept_id   cat_id store_id state_id      d  demand  rol_mean_t7_l0  rol_mean_t14_l0  rol_std_t7_l0  rol_std_t14_l0  ewm_mean_t7_l0  ewm_mean_t14_l0  ewm_std_t7_l0  ewm_std_t14_l0  rol_mean_t7_l30  rol_mean_t14_l30  rol_std_t7_l30  rol_std_t14_l30  ewm_mean_t7_l30  ewm_mean_t14_l30  ewm_std_t7_l30  ewm_std_t14_l30  rol_mean_t7_l180  rol_mean_t14_l180  rol_std_t7_l180  rol_std_t14_l180  ewm_mean_t7_l180  ewm_mean_t14_l180  ewm_std_t7_l180  ewm_std_t14_l180  wday  month  event_name_1  event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  event_name_1_in_1d  event_name_1_in_3d  event_name_1_in_7d\n",
              "5915060  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1       CA  d_195       0        0.000000         0.000000       0.000000        0.000000        0.000000         0.000000       0.000000        0.000000         0.000000          0.000000        0.000000         0.000000         0.000000          0.000000        0.000000         0.000000               0.0                0.0              0.0               0.0               0.0                0.0              0.0               0.0     6      8            19             2             3             1        0        1        1                   0                   0                   0\n",
              "5915061  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1       CA  d_195       0        0.285645         0.142822       0.488037        0.363037        0.157593         0.151123       0.377197        0.364502         0.142822          0.285645        0.377930         0.468750         0.209961          0.194702        0.421631         0.402832               0.0                0.0              0.0               0.0               0.0                0.0              0.0               0.0     6      8            19             2             3             1        0        1        1                   0                   0                   0\n",
              "5915062  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1       CA  d_195       0        0.000000         0.000000       0.000000        0.000000        0.000000         0.000000       0.000000        0.000000         0.000000          0.000000        0.000000         0.000000         0.000000          0.000000        0.000000         0.000000               0.0                0.0              0.0               0.0               0.0                0.0              0.0               0.0     6      8            19             2             3             1        0        1        1                   0                   0                   0\n",
              "5915063  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1       CA  d_195       0        1.286133         1.786133       1.112305        1.528320        1.422852         1.542969       1.405273        1.472656         2.142578          2.000000        1.772461         1.753906         2.039062          1.716797        1.822266         1.758789               0.0                0.0              0.0               0.0               0.0                0.0              0.0               0.0     6      8            19             2             3             1        0        1        1                   0                   0                   0\n",
              "5915064  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1       CA  d_195       0        0.285645         0.714355       0.755859        1.204102        0.553223         0.482910       1.042969        1.035156         0.000000          0.071411        0.000000         0.267334         0.178711          0.442871        0.812012         1.246094               0.0                0.0              0.0               0.0               0.0                0.0              0.0               0.0     6      8            19             2             3             1        0        1        1                   0                   0                   0"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(30490,)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(3049,)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(7,)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(3,)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(3,)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(1719,)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhckDPOgPm7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcfFtz8NnRrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def emb_init(x):\n",
        "    x = x.weight.data\n",
        "    std = 2/(x.size(1)+1)\n",
        "    torch.nn.init.normal_(x, mean=0, std=std)\n",
        "    # sc = 2/(x.size(1)+1)\n",
        "    # x.uniform_(-sc,sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ52S7zqe0pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, ninp, batch_size, nlayers=8, dropout=0.2):\n",
        "        super(LSTMModel, self).__init__()\n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.rnn1 = nn.LSTM(ninp, 32, nlayers, dropout=dropout)\n",
        "        self.fc1 = nn.Linear(32, 16)\n",
        "        self.fc2 = nn.Linear(16, 1)\n",
        "        # self.fc3 = nn.Linear(8, 1)\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.ninp = ninp\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.view(len(x), 1, -1)\n",
        "        x, hid = self.rnn1(x)\n",
        "        x = self.dropout(self.fc1(x).sum(1))\n",
        "        # x = self.dropout(self.fc1(x))\n",
        "        x = self.dropout(self.fc2(x))\n",
        "        # x = self.dropout(self.fc3(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKIjMGmhmmgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Embedding(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
        "    \n",
        "    def __init__(self, emb_szs, batch_size=64, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(r, c) for r, c in emb_szs])\n",
        "        for i in self.embeddings: emb_init(i)\n",
        "\n",
        "        emb_len = sum(i.embedding_dim for i in self.embeddings)\n",
        "\n",
        "        self.fc1 = nn.Linear(emb_len, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = [emb(x[:, i].long()) for i, emb in enumerate(self.embeddings)]\n",
        "        x = torch.cat(x, dim=1)\n",
        "        # x = self.drop(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        # x = self.dropout(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        # x = self.dropout(self.fc3(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz6Pbn2ib_QV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_Emb_Model(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, emb_szs, cont_len, nlayers=8, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.bn = nn.BatchNorm1d(cont_len)\n",
        "\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(r, c) for r, c in emb_szs])\n",
        "        for i in self.embeddings: emb_init(i)\n",
        "        emb_len = sum(i.embedding_dim for i in self.embeddings)\n",
        "        ninp = emb_len + cont_len\n",
        "\n",
        "        self.rnn1 = nn.LSTM(ninp, 8, nlayers, dropout=dropout)\n",
        "        # self.fc0 = nn.Linear(ninp, 64)\n",
        "\n",
        "        self.fc1 = nn.Linear(8, 1)\n",
        "        # self.fc2 = nn.Linear(16, 1)\n",
        "        # self.fc3 = nn.Linear(16, 1)\n",
        "\n",
        "    def forward(self, x_cont, x_cat):\n",
        "\n",
        "        x_cat = [emb(x_cat[:, i].long()) for i, emb in enumerate(self.embeddings)]\n",
        "        x_cat = torch.cat(x_cat, dim=1)\n",
        "        x_cont = self.bn(x_cont)\n",
        "        x = self.dropout(torch.cat([x_cont, x_cat], dim=1))\n",
        "        x = x.view(len(x), 1, -1)\n",
        "\n",
        "        x, hid = self.rnn1(x)\n",
        "        x = self.dropout(self.fc1(x).sum(1))\n",
        "\n",
        "        # x = self.dropout(self.fc0(x))\n",
        "        # x = self.dropout(self.fc1(x))\n",
        "        # x = self.dropout(self.fc2(x))\n",
        "\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tj5BIQDD_I9M",
        "colab": {}
      },
      "source": [
        "class LSTM_Emb_Model_2(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, emb_szs, cont_len, nlayers=7, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.bn = nn.BatchNorm1d(cont_len)\n",
        "\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(r, c) for r, c in emb_szs])\n",
        "        for i in self.embeddings: emb_init(i)\n",
        "        emb_len = sum(i.embedding_dim for i in self.embeddings)\n",
        "        ninp = emb_len + cont_len\n",
        "\n",
        "        self.rnn1 = nn.LSTM(cont_len, 14, nlayers, dropout=dropout, bidirectional=True)\n",
        "        # self.fc_cats = nn.Linear(emb_len, 1)\n",
        "        self.fc1 = nn.Linear(emb_len+28, 256)\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x_cont, x_cat):\n",
        "\n",
        "        x_cat = [emb(x_cat[:, i].long()) for i, emb in enumerate(self.embeddings)]\n",
        "        x_cat = torch.cat(x_cat, dim=1)\n",
        "        # x_cat = self.dropout(self.fc_cats(x_cat))\n",
        "\n",
        "        x_cont = self.bn(x_cont)\n",
        "        x_cont = x_cont.view(len(x_cont), 1, -1)\n",
        "        x_cont, hid = self.rnn1(x_cont)\n",
        "        x_cont = x_cont.sum(1)\n",
        "\n",
        "        x = self.dropout(torch.cat([x_cont, x_cat], dim=1))\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jMOJ5EhNw4Na",
        "colab": {}
      },
      "source": [
        "class RNN_Emb_Model(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, emb_szs, cont_len, nlayers=7, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.bn = nn.BatchNorm1d(cont_len)\n",
        "\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(r, c) for r, c in emb_szs])\n",
        "        for i in self.embeddings: emb_init(i)\n",
        "        emb_len = sum(i.embedding_dim for i in self.embeddings)\n",
        "        ninp = emb_len + cont_len\n",
        "\n",
        "        self.rnn1 = nn.RNN(cont_len, 30, nlayers, dropout=dropout, bidirectional=True)\n",
        "        # self.fc_cats = nn.Linear(emb_len, 1)\n",
        "        self.fc1 = nn.Linear(emb_len+30*2, 256)\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x_cont, x_cat):\n",
        "\n",
        "        x_cat = [emb(x_cat[:, i].long()) for i, emb in enumerate(self.embeddings)]\n",
        "        x_cat = torch.cat(x_cat, dim=1)\n",
        "        # x_cat = self.dropout(self.fc_cats(x_cat))\n",
        "\n",
        "        x_cont = self.bn(x_cont)\n",
        "        x_cont = x_cont.view(len(x_cont), 1, -1)\n",
        "        x_cont, hid = self.rnn1(x_cont)\n",
        "        x_cont = x_cont.sum(1)\n",
        "\n",
        "        x = self.dropout(torch.cat([x_cont, x_cat], dim=1))\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gzu6xjlkY2V0",
        "colab": {}
      },
      "source": [
        "class RNN_Emb_Exp_Model(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, emb_szs, cont_len, nlayers=7, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.bn = nn.BatchNorm1d(cont_len)\n",
        "\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(r, c) for r, c in emb_szs])\n",
        "        for i in self.embeddings: emb_init(i)\n",
        "        emb_len = sum(i.embedding_dim for i in self.embeddings)\n",
        "        ninp = emb_len + cont_len\n",
        "\n",
        "        self.rnn1 = nn.RNN(cont_len, 30, nlayers, dropout=dropout, bidirectional=True)\n",
        "        # self.fc_cats = nn.Linear(emb_len, 1)\n",
        "        self.fc1 = nn.Linear(emb_len+30*2, 256)\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x_cont, x_cat):\n",
        "\n",
        "        x_cat = [emb(x_cat[:, i].long()) for i, emb in enumerate(self.embeddings)]\n",
        "        x_cat = torch.cat(x_cat, dim=1)\n",
        "        # x_cat = self.dropout(self.fc_cats(x_cat))\n",
        "\n",
        "        # x_cont = torch.log1p(x_cont)\n",
        "        x_cont = self.bn(x_cont)\n",
        "        x_cont = x_cont.view(len(x_cont), 1, -1)\n",
        "        x_cont, hid = self.rnn1(x_cont)\n",
        "        x_cont = x_cont.sum(1)\n",
        "        # x_cont = torch.expm1(x_cont)\n",
        "\n",
        "        x = self.dropout(torch.cat([x_cont, x_cat], dim=1))\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtAKaZMDQt8V",
        "colab_type": "text"
      },
      "source": [
        "#Checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FErFlS67dvG",
        "colab_type": "text"
      },
      "source": [
        "#Data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApBXRDGKlneA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nums = params_df\n",
        "cats = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'wday', 'month', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
        "bools = ['snap_CA', 'snap_TX', 'snap_WI', 'event_name_1_in_1d', 'event_name_1_in_3d', 'event_name_1_in_7d']\n",
        "\n",
        "get_cat = FunctionTransformer(lambda df: df.loc[:, cats], validate=False)\n",
        "get_num = FunctionTransformer(lambda df: df.loc[:, nums], validate=False)\n",
        "get_bool = FunctionTransformer(lambda df: df.loc[:, bools], validate=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv-0OMTeUEfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#masks for nn eval\n",
        "test_edge_start = 1886 #1913-28+1\n",
        "test_edge_end = 1913 #1913\n",
        "\n",
        "test_mask_start_ind = df[df.d == 'd_'+str(test_edge_start)].index[0]\n",
        "test_mask_end_ind = df[df.d == 'd_'+str(test_edge_end)].index[-1]\n",
        "# test_mask = df.loc[test_mask_start_ind:test_mask_end_ind, :]\n",
        "\n",
        "val_edge_start = 1856 #1886-30+1\n",
        "val_edge_end = 1885 #1913-28+1\n",
        "\n",
        "val_mask_start_ind = df[df.d == 'd_'+str(val_edge_start)].index[0]\n",
        "val_mask_end_ind = df[df.d == 'd_'+str(val_edge_end)].index[-1]\n",
        "# val_mask = df.loc[val_mask_start_ind:val_mask_end_ind, :]\n",
        "\n",
        "# train_edge_start = 1095\n",
        "train_edge_start = 195\n",
        "# train_edge_start = 1676\n",
        "# train_edge_start = 1126\n",
        "train_edge_end = 1855\n",
        "\n",
        "train_mask_start_ind = df[df.d == 'd_'+str(train_edge_start)].index[0]\n",
        "train_mask_end_ind = df[df.d == 'd_'+str(train_edge_end)].index[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGv-FOHJXthU",
        "colab_type": "code",
        "outputId": "12466bcb-40a8-4176-9dc3-8c148a94c521",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test = df.loc[test_mask_start_ind:test_mask_end_ind, nums+cats+bools]\n",
        "y_test = df.loc[test_mask_start_ind:test_mask_end_ind, :]['demand']\n",
        "\n",
        "display(X_test.shape)\n",
        "display(y_test.shape)\n",
        "\n",
        "X_val = df.loc[val_mask_start_ind:val_mask_end_ind, nums+cats+bools]\n",
        "y_val = df.loc[val_mask_start_ind:val_mask_end_ind, :]['demand']\n",
        "\n",
        "display(X_val.shape)\n",
        "display(y_val.shape)\n",
        "\n",
        "X = df.loc[train_mask_start_ind:train_mask_end_ind, nums+cats+bools]\n",
        "y = df.loc[train_mask_start_ind:train_mask_end_ind, :]['demand']\n",
        "\n",
        "display(X.shape)\n",
        "display(y.shape)\n",
        "\n",
        "# display(df.shape)\n",
        "# del df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(853720, 42)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(853720,)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(914700, 42)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(914700,)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(50643890, 42)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(50643890,)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKUAoGgl3dXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pipeline obviously\n",
        "pl = Pipeline_IMB([    \n",
        "    ('union_outer', FeatureUnion(transformer_list=[\n",
        "#         ('get_nums', Pipeline([\n",
        "#             ('get_num', get_num),\n",
        "# #             ('discretizer', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')),\n",
        "#         ])),\n",
        "        ('get_cat', Pipeline([\n",
        "            ('get_cat', get_cat),\n",
        "            ('lab_enc', OrdinalEncoder())\n",
        "            # ('ohe', OneHotEncoder(dtype='uint8', handle_unknown='ignore'))\n",
        "        ])),\n",
        "        ('get_bools', Pipeline([\n",
        "            ('get_num', get_bool),\n",
        "#             ('discretizer', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')),\n",
        "        ])),\n",
        "    ], n_jobs=1, verbose=True)),\n",
        "    \n",
        "#     ('dim_red', SelectKBest(f_regression, 5000)),\n",
        "#     ('sampling', SMOTE(sampling_strategy='auto', n_jobs=12)),\n",
        "#     ('decomp', TruncatedSVD(n_components=100)),\n",
        "#     ('dim_red', SelectKBest(chi2, 10000)),\n",
        "#     ('imp', SimpleImputer(strategy=\"median\")),\n",
        "#     ('inter', SparseInteractions(degree=2)),\n",
        "#     ('inter', PolynomialFeatures(degree=2, order='F')),\n",
        "    # ('scale', MaxAbsScaler()),\n",
        "    # ('scale', StandardScaler()),\n",
        "#     ('sfm', SelectFromModel(xgb.XGBRegressor(max_depth=100, tree_method='approx', n_jobs=16), threshold='0.5*mean')),\n",
        "#     ('dim_red', SelectKBest(chi2, 50)),\n",
        "#     ('clf', LinearRegression(n_jobs=-1))\n",
        "#     ('clf', LogisticRegression(class_weight='balanced', n_jobs=12))\n",
        "#     ('sfm', SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=3), threshold=0.015)),\n",
        "#     ('clf', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=7))\n",
        "#     ('sfm', SelectFromModel(xgb.XGBRFRegressor(tree_method='hist', random_state=42, n_jobs=12), threshold=0.015)),\n",
        "#     ('xgb', MultiOutputRegressor(xgb.XGBRFRegressor(objective='reg:squarederror', max_depth=45, tree_method='hist', n_jobs=12,random_state=42)))\n",
        "#     ('xgb', xgb.XGBRegressor(max_depth=100, tree_method='approx', n_jobs=7))\n",
        "#     ('clf', LogisticRegression(class_weight='balanced', n_jobs=12))\n",
        "#     ('clf', RandomForestClassifier(class_weight='balanced', n_jobs=12))\n",
        "    # ('svc', NuSVR(degree=3, kernel='poly'))\n",
        "#     ('nn', MLPRegressor(hidden_layer_sizes=(100, 100, 100, 100)))\n",
        "#     ('svc', SVC(class_weight='balanced'))\n",
        "#     ('clf', GradientBoostingRegressor(loss= 'huber', max_depth=10))\n",
        "#     ('clf', MLPRegressor())\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH1RdDWFbkRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cat_encoder(pandas_df, cat_cols_list, dicts=None):\n",
        "    if dicts == None: dicts_ = []\n",
        "    \n",
        "    for i, col in enumerate(cat_cols_list):\n",
        "        if dicts == None:\n",
        "            dict_ = {o:i for i, o in enumerate(pandas_df[col].unique())}\n",
        "            dicts_.append(dict_)\n",
        "        else: dict_ = dicts[i]\n",
        "\n",
        "        pandas_df.loc[:, col] = pandas_df[col].apply(lambda x: dict_[x]).astype('uint16')\n",
        "    \n",
        "    return dicts\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "823xaw6qc31z",
        "colab_type": "code",
        "outputId": "fd4dd97c-d5cf-4a2a-fa86-9eedf43163c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "dicts = cat_encoder(X, cats)\n",
        "cat_encoder(X_val, cats, dicts=dicts)\n",
        "cat_encoder(X_test, cats, dicts=dicts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9min 54s, sys: 1.04 s, total: 9min 56s\n",
            "Wall time: 9min 55s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zw2AX1_paZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_torch = pl.fit_transform(X)\n",
        "# X_val_torch = pl.transform(X_val)\n",
        "# X_test_torch = pl.transform(X_test)\n",
        "\n",
        "# X_torch = X\n",
        "# X_val_torch = X_val\n",
        "# X_test_torch = X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I4WqnIYaXwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 30490\n",
        "\n",
        "##### NUMS\n",
        "try:\n",
        "    X_nums_t = torch.tensor(X[nums].values)\n",
        "    X_nums_val_t = torch.tensor(X_val[nums].values, requires_grad=False)\n",
        "    X_nums_test_t = torch.tensor(X_test[nums].values, requires_grad=False)\n",
        "except:\n",
        "    X_nums_t = torch.tensor(X[nums].values.astype('float32'))\n",
        "    X_nums_val_t = torch.tensor(X_val[nums].values.astype('float32'), requires_grad=False)\n",
        "    X_nums_test_t = torch.tensor(X_test[nums].values.astype('float32'), requires_grad=False)\n",
        "##### CATS & BOOLS\n",
        "try:\n",
        "    X_cats_t = torch.tensor(X[cats+bools].values)\n",
        "    X_cats_val_t = torch.tensor(X_val[cats+bools].values, requires_grad=False)\n",
        "    X_cats_test_t = torch.tensor(X_test[cats+bools].values, requires_grad=False)\n",
        "except:\n",
        "    X_cats_t = torch.tensor(X[cats+bools].values.astype('float32'))\n",
        "    X_cats_val_t = torch.tensor(X_val[cats+bools].values.astype('float32'), requires_grad=False)\n",
        "    X_cats_test_t = torch.tensor(X_test[cats+bools].values.astype('float32'), requires_grad=False)\n",
        "\n",
        "y_torch = torch.tensor(y.values.astype('float32')).view(-1, 1)\n",
        "y_val_torch = torch.tensor(y_val.values.astype('float32')).view(-1, 1)\n",
        "y_test_torch = torch.tensor(y_test.values.astype('float32')).view(-1, 1)\n",
        "\n",
        "trainloader = DataLoader(TensorDataset(X_nums_t, X_cats_t, y_torch), batch_size=batch_size)\n",
        "validloader = DataLoader(TensorDataset(X_nums_val_t, X_cats_val_t, y_val_torch), batch_size=batch_size)\n",
        "testloader = DataLoader(TensorDataset(X_nums_test_t, X_cats_test_t, y_test_torch), batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqO9rtHFyaCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
        "# for i, data in enumerate(dataloader):\n",
        "#     data['image'] = data['image'].type(dtype)\n",
        "#     data['label'] = data['label'].type(dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qndlt_uYpaf",
        "colab_type": "code",
        "outputId": "50a73bf1-abdc-499b-ebb0-7d7ad9cd7fbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "def szs_def(df, columns_list):\n",
        "    szs = []\n",
        "    for col in columns_list:\n",
        "        unique = df[col].nunique()\n",
        "        dim_fun = lambda x: int(x) if (x <= 10) else int(np.sqrt(x))\n",
        "        szs.append([unique, dim_fun(unique)])\n",
        "    return szs\n",
        "\n",
        "szs = szs_def(df, df[cats+bools].columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 19 s, sys: 934 ms, total: 19.9 s\n",
            "Wall time: 19.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3ilypsE67gr",
        "colab_type": "text"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHsJ7xldQ0Pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def QLL(predicted, observed):\n",
        "#     p = torch.tensor(1.5)\n",
        "#     QLL = QLL = torch.pow(predicted, (-p))*(((predicted*observed)/(1-p)) - ((torch.pow(predicted, 2))/(2-p)))\n",
        "\n",
        "#     return QLL\n",
        "        \n",
        "# def tweedieloss(predicted, observed):\n",
        "#     '''\n",
        "#     Custom loss fuction designed to minimize the deviance using stochastic gradient descent\n",
        "#     tweedie deviance from McCullagh 1983\n",
        "\n",
        "#     '''\n",
        "#     d = -2*QLL(predicted, observed)\n",
        "# #     loss = (weight*d)/1\n",
        "\n",
        "\n",
        "#     return torch.mean(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTwzOeVKPnB7",
        "colab_type": "code",
        "outputId": "127ac88c-1a13-4daa-f6c4-39d2900ecae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "# device = torch.device(\"cpu\")\n",
        "\n",
        "model = RNN_Emb_Model(emb_szs=szs, cont_len=len(nums))\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "model.to(device)\n",
        "model.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN_Emb_Model(\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (embeddings): ModuleList(\n",
              "    (0): Embedding(30490, 174)\n",
              "    (1): Embedding(3049, 55)\n",
              "    (2): Embedding(7, 7)\n",
              "    (3): Embedding(3, 3)\n",
              "    (4): Embedding(10, 10)\n",
              "    (5): Embedding(3, 3)\n",
              "    (6): Embedding(7, 7)\n",
              "    (7): Embedding(12, 3)\n",
              "    (8): Embedding(31, 5)\n",
              "    (9): Embedding(5, 5)\n",
              "    (10): Embedding(4, 4)\n",
              "    (11): Embedding(3, 3)\n",
              "    (12): Embedding(2, 2)\n",
              "    (13): Embedding(2, 2)\n",
              "    (14): Embedding(2, 2)\n",
              "    (15): Embedding(2, 2)\n",
              "    (16): Embedding(2, 2)\n",
              "    (17): Embedding(2, 2)\n",
              "  )\n",
              "  (rnn1): LSTM(24, 30, num_layers=7, dropout=0.2, bidirectional=True)\n",
              "  (fc1): Linear(in_features=351, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az0JdKTUPnJa",
        "colab_type": "code",
        "outputId": "ae82be1b-b748-4a4e-f8bd-439692c629c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "epochs = 1\n",
        "running_loss = 0\n",
        "print_every = 15\n",
        "for epoch in range(epochs):\n",
        "        for batch_ind, (inputs_cont, inputs_cat, labels) in enumerate(trainloader):\n",
        "\n",
        "            # Move input and label tensors to the default device/\n",
        "            inputs_cont, inputs_cat, labels = inputs_cont.to(device), inputs_cat.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logps = model.forward(inputs_cont.float(), inputs_cat.float())\n",
        "            loss = criterion(logps, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            gc.collect()\n",
        "\n",
        "            if (batch_ind+1) % print_every == 0:\n",
        "                valid_loss = 0\n",
        "                accuracy = 0\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    for inputs_cont, inputs_cat, labels in validloader:\n",
        "                        inputs_cont, inputs_cat, labels = inputs_cont.to(device), inputs_cat.to(device), labels.to(device)\n",
        "\n",
        "                        logps = model.forward(inputs_cont.float(), inputs_cat.float())\n",
        "                        batch_loss = criterion(logps, labels)\n",
        "\n",
        "                        valid_loss += batch_loss.item()\n",
        "\n",
        "                        # Calculate accuracy\n",
        "                        # ps = torch.exp(logps)\n",
        "                        # top_p, top_class = ps.topk(1, dim=1)\n",
        "                        # equals = top_class == labels.view(*top_class.shape)\n",
        "                        # accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "                print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "                      f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
        "                      f\"Valid loss: {valid_loss/len(validloader):.3f}.. \"\n",
        "                    #   f\"Valid accuracy: {accuracy/len(validloader):.3f}\"\n",
        "                    )\n",
        "                # gpu_info = !nvidia-smi\n",
        "                # gpu_info = '\\n'.join(gpu_info)\n",
        "                # print(gpu_info)\n",
        "                model.train()\n",
        "                running_loss = 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1.. Train loss: 14.589.. Valid loss: 15.067.. \n",
            "Epoch 1/1.. Train loss: 12.737.. Valid loss: 14.818.. \n",
            "Epoch 1/1.. Train loss: 12.526.. Valid loss: 14.481.. \n",
            "Epoch 1/1.. Train loss: 18.987.. Valid loss: 14.072.. \n",
            "Epoch 1/1.. Train loss: 16.421.. Valid loss: 13.693.. \n",
            "Epoch 1/1.. Train loss: 15.398.. Valid loss: 13.483.. \n",
            "Epoch 1/1.. Train loss: 18.198.. Valid loss: 13.268.. \n",
            "Epoch 1/1.. Train loss: 14.639.. Valid loss: 13.286.. \n",
            "Epoch 1/1.. Train loss: 18.545.. Valid loss: 12.917.. \n",
            "Epoch 1/1.. Train loss: 17.611.. Valid loss: 12.454.. \n",
            "Epoch 1/1.. Train loss: 14.009.. Valid loss: 12.176.. \n",
            "Epoch 1/1.. Train loss: 13.351.. Valid loss: 12.273.. \n",
            "Epoch 1/1.. Train loss: 13.755.. Valid loss: 11.995.. \n",
            "Epoch 1/1.. Train loss: 12.024.. Valid loss: 12.280.. \n",
            "Epoch 1/1.. Train loss: 11.951.. Valid loss: 11.707.. \n",
            "Epoch 1/1.. Train loss: 11.249.. Valid loss: 12.102.. \n",
            "Epoch 1/1.. Train loss: 11.907.. Valid loss: 11.254.. \n",
            "Epoch 1/1.. Train loss: 10.060.. Valid loss: 11.633.. \n",
            "Epoch 1/1.. Train loss: 11.703.. Valid loss: 10.941.. \n",
            "Epoch 1/1.. Train loss: 10.940.. Valid loss: 11.399.. \n",
            "Epoch 1/1.. Train loss: 13.495.. Valid loss: 10.691.. \n",
            "Epoch 1/1.. Train loss: 13.171.. Valid loss: 10.621.. \n",
            "Epoch 1/1.. Train loss: 11.780.. Valid loss: 9.823.. \n",
            "Epoch 1/1.. Train loss: 10.312.. Valid loss: 9.632.. \n",
            "Epoch 1/1.. Train loss: 13.026.. Valid loss: 9.527.. \n",
            "Epoch 1/1.. Train loss: 9.800.. Valid loss: 9.361.. \n",
            "Epoch 1/1.. Train loss: 9.644.. Valid loss: 9.131.. \n",
            "Epoch 1/1.. Train loss: 8.491.. Valid loss: 9.038.. \n",
            "Epoch 1/1.. Train loss: 8.110.. Valid loss: 8.897.. \n",
            "Epoch 1/1.. Train loss: 6.499.. Valid loss: 8.792.. \n",
            "Epoch 1/1.. Train loss: 7.758.. Valid loss: 8.727.. \n",
            "Epoch 1/1.. Train loss: 7.758.. Valid loss: 8.553.. \n",
            "Epoch 1/1.. Train loss: 7.289.. Valid loss: 8.632.. \n",
            "Epoch 1/1.. Train loss: 10.236.. Valid loss: 8.388.. \n",
            "Epoch 1/1.. Train loss: 9.380.. Valid loss: 8.454.. \n",
            "Epoch 1/1.. Train loss: 5.860.. Valid loss: 8.286.. \n",
            "Epoch 1/1.. Train loss: 9.041.. Valid loss: 8.808.. \n",
            "Epoch 1/1.. Train loss: 7.218.. Valid loss: 8.063.. \n",
            "Epoch 1/1.. Train loss: 7.957.. Valid loss: 8.128.. \n",
            "Epoch 1/1.. Train loss: 6.614.. Valid loss: 7.875.. \n",
            "Epoch 1/1.. Train loss: 8.052.. Valid loss: 7.928.. \n",
            "Epoch 1/1.. Train loss: 5.470.. Valid loss: 7.764.. \n",
            "Epoch 1/1.. Train loss: 6.674.. Valid loss: 7.734.. \n",
            "Epoch 1/1.. Train loss: 5.780.. Valid loss: 7.619.. \n",
            "Epoch 1/1.. Train loss: 8.906.. Valid loss: 7.745.. \n",
            "Epoch 1/1.. Train loss: 7.988.. Valid loss: 7.536.. \n",
            "Epoch 1/1.. Train loss: 8.296.. Valid loss: 7.556.. \n",
            "Epoch 1/1.. Train loss: 7.081.. Valid loss: 7.535.. \n",
            "Epoch 1/1.. Train loss: 8.516.. Valid loss: 7.752.. \n",
            "Epoch 1/1.. Train loss: 11.837.. Valid loss: 7.551.. \n",
            "Epoch 1/1.. Train loss: 17.950.. Valid loss: 7.687.. \n",
            "Epoch 1/1.. Train loss: 11.115.. Valid loss: 7.650.. \n",
            "Epoch 1/1.. Train loss: 8.162.. Valid loss: 7.526.. \n",
            "Epoch 1/1.. Train loss: 6.518.. Valid loss: 7.346.. \n",
            "Epoch 1/1.. Train loss: 6.497.. Valid loss: 7.329.. \n",
            "Epoch 1/1.. Train loss: 7.457.. Valid loss: 7.208.. \n",
            "Epoch 1/1.. Train loss: 9.327.. Valid loss: 7.083.. \n",
            "Epoch 1/1.. Train loss: 7.394.. Valid loss: 7.165.. \n",
            "Epoch 1/1.. Train loss: 9.003.. Valid loss: 6.952.. \n",
            "Epoch 1/1.. Train loss: 6.021.. Valid loss: 6.907.. \n",
            "Epoch 1/1.. Train loss: 7.201.. Valid loss: 6.819.. \n",
            "Epoch 1/1.. Train loss: 6.953.. Valid loss: 6.752.. \n",
            "Epoch 1/1.. Train loss: 6.383.. Valid loss: 6.724.. \n",
            "Epoch 1/1.. Train loss: 5.424.. Valid loss: 6.645.. \n",
            "Epoch 1/1.. Train loss: 6.257.. Valid loss: 6.693.. \n",
            "Epoch 1/1.. Train loss: 6.192.. Valid loss: 6.625.. \n",
            "Epoch 1/1.. Train loss: 5.837.. Valid loss: 6.614.. \n",
            "Epoch 1/1.. Train loss: 5.518.. Valid loss: 6.523.. \n",
            "Epoch 1/1.. Train loss: 6.267.. Valid loss: 6.479.. \n",
            "Epoch 1/1.. Train loss: 5.510.. Valid loss: 6.509.. \n",
            "Epoch 1/1.. Train loss: 6.620.. Valid loss: 6.490.. \n",
            "Epoch 1/1.. Train loss: 5.779.. Valid loss: 6.476.. \n",
            "Epoch 1/1.. Train loss: 6.756.. Valid loss: 6.470.. \n",
            "Epoch 1/1.. Train loss: 5.754.. Valid loss: 6.461.. \n",
            "Epoch 1/1.. Train loss: 5.368.. Valid loss: 6.444.. \n",
            "Epoch 1/1.. Train loss: 5.349.. Valid loss: 6.409.. \n",
            "Epoch 1/1.. Train loss: 5.611.. Valid loss: 6.361.. \n",
            "Epoch 1/1.. Train loss: 5.044.. Valid loss: 6.277.. \n",
            "Epoch 1/1.. Train loss: 4.652.. Valid loss: 6.217.. \n",
            "Epoch 1/1.. Train loss: 5.021.. Valid loss: 6.176.. \n",
            "Epoch 1/1.. Train loss: 5.719.. Valid loss: 6.177.. \n",
            "Epoch 1/1.. Train loss: 5.021.. Valid loss: 6.162.. \n",
            "Epoch 1/1.. Train loss: 5.573.. Valid loss: 6.131.. \n",
            "Epoch 1/1.. Train loss: 5.299.. Valid loss: 6.136.. \n",
            "Epoch 1/1.. Train loss: 4.696.. Valid loss: 6.036.. \n",
            "Epoch 1/1.. Train loss: 5.494.. Valid loss: 6.030.. \n",
            "Epoch 1/1.. Train loss: 4.814.. Valid loss: 6.192.. \n",
            "Epoch 1/1.. Train loss: 5.571.. Valid loss: 5.974.. \n",
            "Epoch 1/1.. Train loss: 4.976.. Valid loss: 5.944.. \n",
            "Epoch 1/1.. Train loss: 5.127.. Valid loss: 5.914.. \n",
            "Epoch 1/1.. Train loss: 4.646.. Valid loss: 5.884.. \n",
            "Epoch 1/1.. Train loss: 4.799.. Valid loss: 5.884.. \n",
            "Epoch 1/1.. Train loss: 5.384.. Valid loss: 5.872.. \n",
            "Epoch 1/1.. Train loss: 6.895.. Valid loss: 5.872.. \n",
            "Epoch 1/1.. Train loss: 5.879.. Valid loss: 5.863.. \n",
            "Epoch 1/1.. Train loss: 5.357.. Valid loss: 5.859.. \n",
            "Epoch 1/1.. Train loss: 4.883.. Valid loss: 5.818.. \n",
            "Epoch 1/1.. Train loss: 5.919.. Valid loss: 5.860.. \n",
            "Epoch 1/1.. Train loss: 4.762.. Valid loss: 5.843.. \n",
            "Epoch 1/1.. Train loss: 5.406.. Valid loss: 5.816.. \n",
            "Epoch 1/1.. Train loss: 5.087.. Valid loss: 5.793.. \n",
            "Epoch 1/1.. Train loss: 5.594.. Valid loss: 5.706.. \n",
            "Epoch 1/1.. Train loss: 4.539.. Valid loss: 5.684.. \n",
            "Epoch 1/1.. Train loss: 5.032.. Valid loss: 5.630.. \n",
            "Epoch 1/1.. Train loss: 5.049.. Valid loss: 5.569.. \n",
            "Epoch 1/1.. Train loss: 5.935.. Valid loss: 5.693.. \n",
            "Epoch 1/1.. Train loss: 5.516.. Valid loss: 5.541.. \n",
            "Epoch 1/1.. Train loss: 5.644.. Valid loss: 5.476.. \n",
            "Epoch 1/1.. Train loss: 4.432.. Valid loss: 5.446.. \n",
            "Epoch 1/1.. Train loss: 5.879.. Valid loss: 5.406.. \n",
            "CPU times: user 12h 1min 55s, sys: 6min 44s, total: 12h 8min 40s\n",
            "Wall time: 12h 8min 32s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQm1AVh8o4ex",
        "colab_type": "code",
        "outputId": "b2c5ccaa-7906-4e7e-da76-4472989e640e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "torch.save(model, './drive/My Drive/Colab Notebooks/model_LSTM30_Emb')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type RNN_Emb_Model. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgUp5lT7dmVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RNN bidir hid=30\n",
        "Epoch 1/1.. Train loss: 5.477.. Valid loss: 5.005.. \n",
        "Epoch 1/1.. Train loss: 5.027.. Valid loss: 4.953.. \n",
        "Epoch 1/1.. Train loss: 5.269.. Valid loss: 4.812.. \n",
        "Epoch 1/1.. Train loss: 4.136.. Valid loss: 4.818.. \n",
        "Epoch 1/1.. Train loss: 5.560.. Valid loss: 4.782.. \n",
        "\n",
        "# LSTM bidir hid=30\n",
        "Epoch 1/1.. Train loss: 5.935.. Valid loss: 5.693.. \n",
        "Epoch 1/1.. Train loss: 5.516.. Valid loss: 5.541.. \n",
        "Epoch 1/1.. Train loss: 5.644.. Valid loss: 5.476.. \n",
        "Epoch 1/1.. Train loss: 4.432.. Valid loss: 5.446.. \n",
        "Epoch 1/1.. Train loss: 5.879.. Valid loss: 5.406.. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7RPrHjHsonI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RNN hid=30\n",
        "Epoch 1/5.. Train loss: 2.764.. Valid loss: 1.942.. \n",
        "Epoch 1/5.. Train loss: 2.572.. Valid loss: 1.782.. \n",
        "Epoch 1/5.. Train loss: 2.842.. Valid loss: 1.937.. \n",
        "Epoch 1/5.. Train loss: 2.340.. Valid loss: 1.724.. \n",
        "Epoch 1/5.. Train loss: 2.934.. Valid loss: 1.726..\n",
        "\n",
        "# RNN bidir hid=30\n",
        "Epoch 1/1.. Train loss: 1.418.. Valid loss: 0.749.. \n",
        "Epoch 1/1.. Train loss: 1.487.. Valid loss: 0.735.. \n",
        "Epoch 1/1.. Train loss: 1.530.. Valid loss: 0.754.. \n",
        "Epoch 1/1.. Train loss: 1.352.. Valid loss: 0.722.. \n",
        "Epoch 1/1.. Train loss: 1.618.. Valid loss: 0.687.. \n",
        "\n",
        "# RNN bidir hid=30 Exp1(Log1(X))\n",
        "Epoch 1/1.. Train loss: 1.627.. Valid loss: 0.927.. \n",
        "Epoch 1/1.. Train loss: 1.767.. Valid loss: 1.041.. \n",
        "Epoch 1/1.. Train loss: 1.779.. Valid loss: 0.882.. \n",
        "Epoch 1/1.. Train loss: 1.528.. Valid loss: 0.900.. \n",
        "Epoch 1/1.. Train loss: 1.877.. Valid loss: 0.921.. \n",
        "\n",
        "# RNN bidir hid=60\n",
        "Epoch 1/1.. Train loss: 0.942.. Valid loss: 0.331.. \n",
        "Epoch 1/1.. Train loss: 1.068.. Valid loss: 0.541.. \n",
        "Epoch 1/1.. Train loss: 1.153.. Valid loss: 0.342.. \n",
        "Epoch 1/1.. Train loss: 1.049.. Valid loss: 0.612.. \n",
        "Epoch 1/1.. Train loss: 1.120.. Valid loss: 0.375..  \n",
        "\n",
        "# RNN bidir hid=30 Log1(X) Exp1(y)\n",
        "Epoch 1/2.. Train loss: 2.888.. Valid loss: 1.862.. \n",
        "Epoch 1/2.. Train loss: 2.647.. Valid loss: 1.921.. \n",
        "Epoch 1/2.. Train loss: 3.305.. Valid loss: 1.624.. \n",
        "Epoch 1/2.. Train loss: 2.435.. Valid loss: 1.664.. \n",
        "Epoch 1/2.. Train loss: 3.482.. Valid loss: 1.796..\n",
        "\n",
        "# RNN bidir hid=90\n",
        "Epoch 1/1.. Train loss: 0.795.. Valid loss: 0.255.. \n",
        "Epoch 1/1.. Train loss: 0.992.. Valid loss: 0.407.. \n",
        "Epoch 1/1.. Train loss: 0.994.. Valid loss: 0.261.. \n",
        "Epoch 1/1.. Train loss: 0.885.. Valid loss: 0.349.. \n",
        "Epoch 1/1.. Train loss: 0.917.. Valid loss: 0.391.. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pFQ13RIQaZ3",
        "colab_type": "text"
      },
      "source": [
        "#Loaded models work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEEvSjABQZtq",
        "colab_type": "code",
        "outputId": "4734f1db-554f-4bae-9c52-0559f908cbc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "model = torch.load('./drive/My Drive/Colab Notebooks/model_RNN90_Emb')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.RNN' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41Nw2AVjQ5_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display(df.head())\n",
        "\n",
        "template = df[df.d=='d_180'].iloc[:,:7].copy() # делаю шаблон на 30490 строк"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpIQ9Q7u3dYS",
        "colab_type": "code",
        "outputId": "b0d4ccc3-fed6-495a-b3d3-b9055c9bda9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "df_ = df.copy()\n",
        "d = 'd_1914'\n",
        "template.loc[:, 'd'] = d\n",
        "display(template)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5457710</th>\n",
              "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5457711</th>\n",
              "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_002</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5457712</th>\n",
              "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_003</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5457713</th>\n",
              "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_004</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5457714</th>\n",
              "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_005</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5488195</th>\n",
              "      <td>FOODS_3_823_WI_3_validation</td>\n",
              "      <td>FOODS_3_823</td>\n",
              "      <td>FOODS_3</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>d_1914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5488196</th>\n",
              "      <td>FOODS_3_824_WI_3_validation</td>\n",
              "      <td>FOODS_3_824</td>\n",
              "      <td>FOODS_3</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>d_1914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5488197</th>\n",
              "      <td>FOODS_3_825_WI_3_validation</td>\n",
              "      <td>FOODS_3_825</td>\n",
              "      <td>FOODS_3</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>d_1914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5488198</th>\n",
              "      <td>FOODS_3_826_WI_3_validation</td>\n",
              "      <td>FOODS_3_826</td>\n",
              "      <td>FOODS_3</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>d_1914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5488199</th>\n",
              "      <td>FOODS_3_827_WI_3_validation</td>\n",
              "      <td>FOODS_3_827</td>\n",
              "      <td>FOODS_3</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>d_1914</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    id        item_id    dept_id   cat_id store_id state_id       d\n",
              "5457710  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1       CA  d_1914\n",
              "5457711  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1       CA  d_1914\n",
              "5457712  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1       CA  d_1914\n",
              "5457713  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1       CA  d_1914\n",
              "5457714  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1       CA  d_1914\n",
              "...                                ...            ...        ...      ...      ...      ...     ...\n",
              "5488195    FOODS_3_823_WI_3_validation    FOODS_3_823    FOODS_3    FOODS     WI_3       WI  d_1914\n",
              "5488196    FOODS_3_824_WI_3_validation    FOODS_3_824    FOODS_3    FOODS     WI_3       WI  d_1914\n",
              "5488197    FOODS_3_825_WI_3_validation    FOODS_3_825    FOODS_3    FOODS     WI_3       WI  d_1914\n",
              "5488198    FOODS_3_826_WI_3_validation    FOODS_3_826    FOODS_3    FOODS     WI_3       WI  d_1914\n",
              "5488199    FOODS_3_827_WI_3_validation    FOODS_3_827    FOODS_3    FOODS     WI_3       WI  d_1914\n",
              "\n",
              "[30490 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjTU1VnUNuOM",
        "colab_type": "code",
        "outputId": "2666d368-3d46-4ded-cb70-33f365db6ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "df.loc[58325931:58325933,:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d</th>\n",
              "      <th>demand</th>\n",
              "      <th>rol_mean_t7_l0</th>\n",
              "      <th>rol_mean_t14_l0</th>\n",
              "      <th>rol_std_t7_l0</th>\n",
              "      <th>rol_std_t14_l0</th>\n",
              "      <th>ewm_mean_t7_l0</th>\n",
              "      <th>ewm_mean_t14_l0</th>\n",
              "      <th>ewm_std_t7_l0</th>\n",
              "      <th>ewm_std_t14_l0</th>\n",
              "      <th>rol_mean_t7_l30</th>\n",
              "      <th>rol_mean_t14_l30</th>\n",
              "      <th>rol_std_t7_l30</th>\n",
              "      <th>rol_std_t14_l30</th>\n",
              "      <th>ewm_mean_t7_l30</th>\n",
              "      <th>ewm_mean_t14_l30</th>\n",
              "      <th>ewm_std_t7_l30</th>\n",
              "      <th>ewm_std_t14_l30</th>\n",
              "      <th>rol_mean_t7_l180</th>\n",
              "      <th>rol_mean_t14_l180</th>\n",
              "      <th>rol_std_t7_l180</th>\n",
              "      <th>rol_std_t14_l180</th>\n",
              "      <th>ewm_mean_t7_l180</th>\n",
              "      <th>ewm_mean_t14_l180</th>\n",
              "      <th>ewm_std_t7_l180</th>\n",
              "      <th>ewm_std_t14_l180</th>\n",
              "      <th>wday</th>\n",
              "      <th>month</th>\n",
              "      <th>event_name_1</th>\n",
              "      <th>event_type_1</th>\n",
              "      <th>event_name_2</th>\n",
              "      <th>event_type_2</th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "      <th>event_name_1_in_1d</th>\n",
              "      <th>event_name_1_in_3d</th>\n",
              "      <th>event_name_1_in_7d</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>58325931</th>\n",
              "      <td>HOUSEHOLD_2_515_WI_3_validation</td>\n",
              "      <td>HOUSEHOLD_2_515</td>\n",
              "      <td>HOUSEHOLD_2</td>\n",
              "      <td>HOUSEHOLD</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>d_1913</td>\n",
              "      <td>0</td>\n",
              "      <td>0.142822</td>\n",
              "      <td>0.071411</td>\n",
              "      <td>0.37793</td>\n",
              "      <td>0.267334</td>\n",
              "      <td>0.114929</td>\n",
              "      <td>0.169678</td>\n",
              "      <td>0.399902</td>\n",
              "      <td>0.48291</td>\n",
              "      <td>0.285645</td>\n",
              "      <td>0.142822</td>\n",
              "      <td>0.488037</td>\n",
              "      <td>0.363037</td>\n",
              "      <td>0.242310</td>\n",
              "      <td>0.254639</td>\n",
              "      <td>0.563965</td>\n",
              "      <td>0.662598</td>\n",
              "      <td>0.285645</td>\n",
              "      <td>0.142822</td>\n",
              "      <td>0.755859</td>\n",
              "      <td>0.534668</td>\n",
              "      <td>0.208008</td>\n",
              "      <td>0.168945</td>\n",
              "      <td>0.619141</td>\n",
              "      <td>0.525391</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58325932</th>\n",
              "      <td>HOUSEHOLD_2_516_WI_3_validation</td>\n",
              "      <td>HOUSEHOLD_2_516</td>\n",
              "      <td>HOUSEHOLD_2</td>\n",
              "      <td>HOUSEHOLD</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>d_1913</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071411</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.267334</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>0.158447</td>\n",
              "      <td>0.376221</td>\n",
              "      <td>0.46875</td>\n",
              "      <td>0.142822</td>\n",
              "      <td>0.142822</td>\n",
              "      <td>0.377930</td>\n",
              "      <td>0.363037</td>\n",
              "      <td>0.212036</td>\n",
              "      <td>0.237671</td>\n",
              "      <td>0.534180</td>\n",
              "      <td>0.643555</td>\n",
              "      <td>0.285645</td>\n",
              "      <td>0.142822</td>\n",
              "      <td>0.755859</td>\n",
              "      <td>0.534668</td>\n",
              "      <td>0.182007</td>\n",
              "      <td>0.157715</td>\n",
              "      <td>0.583496</td>\n",
              "      <td>0.509277</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58325933</th>\n",
              "      <td>FOODS_1_001_WI_3_validation</td>\n",
              "      <td>FOODS_1_001</td>\n",
              "      <td>FOODS_1</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>d_1913</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071411</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.267334</td>\n",
              "      <td>0.088013</td>\n",
              "      <td>0.147827</td>\n",
              "      <td>0.353516</td>\n",
              "      <td>0.45459</td>\n",
              "      <td>0.142822</td>\n",
              "      <td>0.142822</td>\n",
              "      <td>0.377930</td>\n",
              "      <td>0.363037</td>\n",
              "      <td>0.185547</td>\n",
              "      <td>0.221802</td>\n",
              "      <td>0.504883</td>\n",
              "      <td>0.624512</td>\n",
              "      <td>0.428467</td>\n",
              "      <td>0.214233</td>\n",
              "      <td>0.786621</td>\n",
              "      <td>0.579102</td>\n",
              "      <td>0.284180</td>\n",
              "      <td>0.213867</td>\n",
              "      <td>0.613281</td>\n",
              "      <td>0.536621</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       id          item_id      dept_id     cat_id store_id state_id       d  demand  rol_mean_t7_l0  rol_mean_t14_l0  rol_std_t7_l0  rol_std_t14_l0  ewm_mean_t7_l0  ewm_mean_t14_l0  ewm_std_t7_l0  ewm_std_t14_l0  rol_mean_t7_l30  rol_mean_t14_l30  rol_std_t7_l30  rol_std_t14_l30  ewm_mean_t7_l30  ewm_mean_t14_l30  ewm_std_t7_l30  ewm_std_t14_l30  rol_mean_t7_l180  rol_mean_t14_l180  rol_std_t7_l180  rol_std_t14_l180  ewm_mean_t7_l180  ewm_mean_t14_l180  ewm_std_t7_l180  ewm_std_t14_l180  wday  month  event_name_1  event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  event_name_1_in_1d  event_name_1_in_3d  event_name_1_in_7d\n",
              "58325931  HOUSEHOLD_2_515_WI_3_validation  HOUSEHOLD_2_515  HOUSEHOLD_2  HOUSEHOLD     WI_3       WI  d_1913       0        0.142822         0.071411        0.37793        0.267334        0.114929         0.169678       0.399902         0.48291         0.285645          0.142822        0.488037         0.363037         0.242310          0.254639        0.563965         0.662598          0.285645           0.142822         0.755859          0.534668          0.208008           0.168945         0.619141          0.525391     2      4            19             2             3             1        0        0        0                   0                   0                   1\n",
              "58325932  HOUSEHOLD_2_516_WI_3_validation  HOUSEHOLD_2_516  HOUSEHOLD_2  HOUSEHOLD     WI_3       WI  d_1913       0        0.000000         0.071411        0.00000        0.267334        0.100586         0.158447       0.376221         0.46875         0.142822          0.142822        0.377930         0.363037         0.212036          0.237671        0.534180         0.643555          0.285645           0.142822         0.755859          0.534668          0.182007           0.157715         0.583496          0.509277     2      4            19             2             3             1        0        0        0                   0                   0                   1\n",
              "58325933      FOODS_1_001_WI_3_validation      FOODS_1_001      FOODS_1      FOODS     WI_3       WI  d_1913       0        0.000000         0.071411        0.00000        0.267334        0.088013         0.147827       0.353516         0.45459         0.142822          0.142822        0.377930         0.363037         0.185547          0.221802        0.504883         0.624512          0.428467           0.214233         0.786621          0.579102          0.284180           0.213867         0.613281          0.536621     2      4            19             2             3             1        0        0        0                   0                   0                   1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noFsF6nHWmmv",
        "colab_type": "code",
        "outputId": "a42f5568-eadf-4ab2-cba1-696ae772d21b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "df.groupby(by='item_id')['demand']\\\n",
        ".transform(lambda x: x.shift(0))\\\n",
        ".rolling(7).mean().astype('float16')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "548833           NaN\n",
              "548834           NaN\n",
              "548835           NaN\n",
              "548836           NaN\n",
              "548837           NaN\n",
              "              ...   \n",
              "58327365    1.000000\n",
              "58327366    0.856934\n",
              "58327367    0.714355\n",
              "58327368    0.856934\n",
              "58327369    0.714355\n",
              "Name: demand, Length: 57778537, dtype: float16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2jKn2N9JWgy",
        "colab_type": "code",
        "outputId": "8ae63d08-2531-4977-b816-7d25b8d645ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "test = df.groupby(by='id')['demand']\\\n",
        ".rolling(7).mean().astype('float16')\n",
        "\n",
        "idx = pd.IndexSlice\n",
        "test.loc[idx['FOODS_3_827_CA_1_validation', :]]\n",
        "\n",
        "\n",
        "# test.loc[slice('FOODS_3_827_CA_1_validation'), slice(None)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                                   \n",
              "FOODS_3_827_CA_1_validation  551868           NaN\n",
              "                             582358           NaN\n",
              "                             612848           NaN\n",
              "                             643338           NaN\n",
              "                             673828           NaN\n",
              "                                           ...   \n",
              "                             58177968    7.714844\n",
              "                             58208458    7.000000\n",
              "                             58238948    7.000000\n",
              "                             58269438    6.714844\n",
              "                             58299928    7.000000\n",
              "Name: demand, Length: 1895, dtype: float16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_naHyT7LVzY",
        "colab_type": "code",
        "outputId": "77cfc832-5d9b-4329-8755-3c4805ea234b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "test.index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiIndex([(    'FOODS_1_001_CA_1_validation',   550432),\n",
              "            (    'FOODS_1_001_CA_1_validation',   580922),\n",
              "            (    'FOODS_1_001_CA_1_validation',   611412),\n",
              "            (    'FOODS_1_001_CA_1_validation',   641902),\n",
              "            (    'FOODS_1_001_CA_1_validation',   672392),\n",
              "            (    'FOODS_1_001_CA_1_validation',   702882),\n",
              "            (    'FOODS_1_001_CA_1_validation',   733372),\n",
              "            (    'FOODS_1_001_CA_1_validation',   763862),\n",
              "            (    'FOODS_1_001_CA_1_validation',   794352),\n",
              "            (    'FOODS_1_001_CA_1_validation',   824842),\n",
              "            ...\n",
              "            ('HOUSEHOLD_2_516_WI_3_validation', 58051522),\n",
              "            ('HOUSEHOLD_2_516_WI_3_validation', 58082012),\n",
              "            ('HOUSEHOLD_2_516_WI_3_validation', 58112502),\n",
              "            ('HOUSEHOLD_2_516_WI_3_validation', 58142992),\n",
              "            ('HOUSEHOLD_2_516_WI_3_validation', 58173482),\n",
              "            ('HOUSEHOLD_2_516_WI_3_validation', 58203972),\n",
              "            ('HOUSEHOLD_2_516_WI_3_validation', 58234462),\n",
              "            ('HOUSEHOLD_2_516_WI_3_validation', 58264952),\n",
              "            ('HOUSEHOLD_2_516_WI_3_validation', 58295442),\n",
              "            ('HOUSEHOLD_2_516_WI_3_validation', 58325932)],\n",
              "           names=['id', None], length=57778537)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz0fGbLCX5AL",
        "colab_type": "code",
        "outputId": "a380ae8c-7e0c-4b00-cd68-9d1ecae5c94e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "df[df.item_id=='FOODS_3_827']['demand']\\\n",
        ".transform(lambda x: x.shift(0))\\\n",
        ".rolling(7).mean().astype('float16')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "551868           NaN\n",
              "554917           NaN\n",
              "557966           NaN\n",
              "561015           NaN\n",
              "564064           NaN\n",
              "              ...   \n",
              "58315173    6.000000\n",
              "58318222    6.429688\n",
              "58321271    3.427734\n",
              "58324320    3.714844\n",
              "58327369    1.857422\n",
              "Name: demand, Length: 18950, dtype: float16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKd7SV0vKLWC",
        "colab_type": "code",
        "outputId": "bc8830b5-d292-4843-acaa-66f4c1415e87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "df[df.item_id=='FOODS_3_826']['demand']\\\n",
        ".transform(lambda x: x.shift(0))\\\n",
        ".rolling(7).mean().astype('float16')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "551867           NaN\n",
              "554916           NaN\n",
              "557965           NaN\n",
              "561014           NaN\n",
              "564063           NaN\n",
              "              ...   \n",
              "58315172    1.713867\n",
              "58318221    1.857422\n",
              "58321270    2.142578\n",
              "58324319    1.857422\n",
              "58327368    1.857422\n",
              "Name: demand, Length: 18950, dtype: float16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYhwnRYnSrkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_ = pd.concat([df_, template], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z060UaA8VHnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG7deLHaVI2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adding_cols(df, lags=[0, 90, 180], macd_angle=False, target_col='demand'):\n",
        "    \n",
        "#     df = df.copy()\n",
        "    \n",
        "    params = []\n",
        "\n",
        "    for lag in lags:\n",
        "        print(lag)\n",
        "    \n",
        "        #rolling mean\n",
        "        for window in [7, 14]:\n",
        "\n",
        "            add_param = df.groupby(by='item_id')[target_col]\\\n",
        "            .transform(lambda x: x.shift(lag))\\\n",
        "            .rolling(window).mean().astype('float16')\n",
        "            \n",
        "            sub_column_name = f'rol_mean_t{window}_l{lag}'\n",
        "            params.append(sub_column_name)\n",
        "            df.loc[:, sub_column_name] = add_param\n",
        "            gc.collect()\n",
        "\n",
        "        #rolling std\n",
        "        for window in [7, 14]:\n",
        "            \n",
        "            add_param = df.groupby(by='item_id')[target_col]\\\n",
        "            .transform(lambda x: x.shift(lag))\\\n",
        "            .rolling(window).std().astype('float16')\n",
        "            \n",
        "            sub_column_name = f'rol_std_t{window}_l{lag}'\n",
        "            params.append(sub_column_name)\n",
        "            df.loc[:, sub_column_name] = add_param\n",
        "            gc.collect()\n",
        "            \n",
        "    #     #rolling max\n",
        "    #     for window in [7, 14, 30]:\n",
        "            \n",
        "    #         add_param = df.groupby(by='item_id')[target_col]\\\n",
        "    #         .transform(lambda x: x.shift(lag))\\\n",
        "    #         .rolling(window).max().astype('float16')\n",
        "            \n",
        "    #         sub_column_name = f'rol_max_t{window}_l{lag}'\n",
        "    #         params.append(sub_column_name)\n",
        "    #         df.loc[:, sub_column_name] = add_param\n",
        "    #         gc.collect()\n",
        "            \n",
        "    #     #rolling min\n",
        "    #     for window in [7, 14, 30]:\n",
        "            \n",
        "    #         add_param = df.groupby(by='item_id')[target_col]\\\n",
        "    #         .transform(lambda x: x.shift(lag))\\\n",
        "    #         .rolling(window).min().astype('float16')\n",
        "            \n",
        "    #         sub_column_name = f'rol_min_t{window}_l{lag}'\n",
        "    #         params.append(sub_column_name)\n",
        "    #         df.loc[:, sub_column_name] = add_param\n",
        "    #         gc.collect()\n",
        "            \n",
        "    #     #rolling skew\n",
        "    #     for window in [7, 14, 30]:\n",
        "            \n",
        "    #         add_param = df.groupby(by='item_id')[target_col]\\\n",
        "    #         .transform(lambda x: x.shift(lag))\\\n",
        "    #         .rolling(window).skew().astype('float16')\n",
        "            \n",
        "    #         sub_column_name = f'rol_skew_t{window}_l{lag}'\n",
        "    #         params.append(sub_column_name)\n",
        "    #         df.loc[:, sub_column_name] = add_param\n",
        "    #         gc.collect()\n",
        "            \n",
        "    #     #rolling kurt\n",
        "    #     for window in [7, 14, 30]:\n",
        "            \n",
        "    #         add_param = df.groupby(by='item_id')[target_col]\\\n",
        "    #         .transform(lambda x: x.shift(lag))\\\n",
        "    #         .rolling(window).kurt().astype('float16')\n",
        "            \n",
        "    #         sub_column_name = f'rol_kurt_t{window}_l{lag}'\n",
        "    #         params.append(sub_column_name)\n",
        "    #         df.loc[:, sub_column_name] = add_param\n",
        "    #         gc.collect()\n",
        "            \n",
        "        #ewm mean    \n",
        "        for window in [7, 14]:\n",
        "            \n",
        "            add_param = df.groupby(by='item_id')[target_col]\\\n",
        "            .transform(lambda x: x.shift(lag))\\\n",
        "            .ewm(window).mean().astype('float16')\n",
        "            \n",
        "            sub_column_name = f'ewm_mean_t{window}_l{lag}'\n",
        "            params.append(sub_column_name)\n",
        "            df.loc[:, sub_column_name] = add_param\n",
        "            gc.collect()\n",
        "            \n",
        "        #ewm std    \n",
        "        for window in [7, 14]:\n",
        "            \n",
        "            add_param = df.groupby(by='item_id')[target_col]\\\n",
        "            .transform(lambda x: x.shift(lag))\\\n",
        "            .ewm(window).std().astype('float16')\n",
        "            \n",
        "            sub_column_name = f'ewm_std_t{window}_l{lag}'\n",
        "            params.append(sub_column_name)\n",
        "            df.loc[:, sub_column_name] = add_param\n",
        "            gc.collect()\n",
        "\n",
        "    #     #macd\n",
        "    #     for short in [4, 7, 9]:\n",
        "    #         add_param = macd(df[nums], short)\n",
        "    #         sub_column_name = f'macd_'+str(short)\n",
        "    #         params.append(sub_column_name)\n",
        "    #         add_param.columns = pd.MultiIndex.from_tuples([(col[0], sub_column_name) for col in add_param.columns])\n",
        "    #         df_out = df_out.join(add_param).sort_index(axis=1)\n",
        "    #         gc.collect()\n",
        "\n",
        "    #         if macd_angle==True:\n",
        "    #             for window in [2, 3, 5]:\n",
        "    #                 add_param = add_param.rolling(window, axis=1).apply(angle, raw=True)\n",
        "    #                 sub_column_name = f'macd_'+str(short)+'_angle_'+str(window)\n",
        "    #                 params.append(sub_column_name)\n",
        "    #                 add_param.columns = pd.MultiIndex.from_tuples([(col[0], sub_column_name) for col in add_param.columns])\n",
        "    #                 df_out = df_out.join(add_param).sort_index(axis=1)\n",
        "    #                 gc.collect()\n",
        "\n",
        "    # gc.collect()\n",
        "    return df, params"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}